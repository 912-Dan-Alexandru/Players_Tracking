{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOLZXjCIsSoRko6NSzaBIKv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQzYzfjlSPNs","executionInfo":{"status":"ok","timestamp":1673815458417,"user_tz":-120,"elapsed":1618,"user":{"displayName":"alex dan","userId":"11093049752083971773"}},"outputId":"c4a0081a-8195-4e7d-a49c-2a0f5e8ae6b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os"],"metadata":{"id":"e3xrnP6VSm0T","executionInfo":{"status":"ok","timestamp":1673815461798,"user_tz":-120,"elapsed":252,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["os.chdir('drive/MyDrive/Colab Notebooks/')"],"metadata":{"id":"U9Ev01gvSqYp","executionInfo":{"status":"ok","timestamp":1673815463183,"user_tz":-120,"elapsed":349,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import load_img\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelBinarizer\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","import pickle\n","from skimage.color import rgb2gray\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","import sys"],"metadata":{"id":"FY7uHhkOozce","executionInfo":{"status":"ok","timestamp":1673815497123,"user_tz":-120,"elapsed":3265,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def detect_jersey_number(img):\n","  # cv2_imshow(img)\n","  bboxes = []\n","  scale_percent = 500\n","\n","  imh = img.shape[0]\n","  imw = img.shape[1]\n","\n","  width = int(img.shape[1] * scale_percent / 100)\n","  height = int(img.shape[0] * scale_percent / 100)\n","  dim = (width, height)\n","    \n","  # resize image\n","  img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n","\n","  hImg = img.shape[0]\n","  wImg = img.shape[1]\n","\n","  #crop\n","  img = img[hImg//10*2:hImg//10*5, wImg//100*10:wImg//100*90]\n","\n","  #grayscale\n","  gray = ~ cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","  #blur\n","  blur = cv2.GaussianBlur(gray, (7,7), 0)\n","\n","  #threshold\n","  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","\n","  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,13))\n","\n","  #dilate\n","  dilate = cv2.dilate(thresh, kernel, iterations=1)\n","\n","  #contours\n","  cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n","  cnts = sorted(cnts, key=lambda x:cv2.boundingRect(x)[0])\n","  \n","  for c in cnts:\n","    x,y,w,h = cv2.boundingRect(c)\n","    if h>img.shape[0]//10*3 and w>img.shape[0]//10*3 and h<img.shape[0]//10*7 :\n","      bboxes.append(((x+imw//2)//5,(y+imh)//5,w//5,h//5))\n","\n","  return bboxes"],"metadata":{"id":"SNeMsqLFCxKG","executionInfo":{"status":"ok","timestamp":1673815551501,"user_tz":-120,"elapsed":873,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["digit_recognition_model = load_model('number_detection_model.h5')"],"metadata":{"id":"wagC3dQuU3Sb","executionInfo":{"status":"ok","timestamp":1673815559701,"user_tz":-120,"elapsed":820,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def identify_number(img):\n","  digits=[]\n","  nr=0\n","\n","  cropped_img=img\n","  width = int(cropped_img.shape[1] * 5)\n","  height = int(cropped_img.shape[0] * 5)\n","  dim = (width, height)\n","    \n","  cropped_img = cv2.resize(cropped_img, (dim), interpolation = cv2.INTER_AREA)\n","  \n","  gray = ~ cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n","  \n","  blur = cv2.GaussianBlur(gray, (7,7), 0)\n","\n","  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","  \n","  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,13))\n","\n","  dilate = cv2.dilate(thresh, kernel, iterations=1)\n","\n","  cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n","\n","  cnts = sorted(cnts, key=lambda x:cv2.boundingRect(x)[0])\n","  for c in cnts:\n","    x,y,w,h = cv2.boundingRect(c)\n","    if h>cropped_img.shape[0]//10*5 and w>cropped_img.shape[0]//4:\n","      \n","      digit_img = cropped_img[y:y+h, x:x+w]\n","      \n","      gray = cv2.cvtColor(digit_img, cv2.COLOR_BGR2GRAY)\n","      blur = cv2.GaussianBlur(gray, (7,7), 0)\n","      thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","      \n","      digit_black_and_white_img = cv2.resize(thresh, (20,20), interpolation = cv2.INTER_AREA)\n","      digit_black_and_white_img = cv2.copyMakeBorder(digit_black_and_white_img, 4, 4, 4, 4, cv2.BORDER_CONSTANT,value=[255, 255, 255])\n","\n","      digit_black_and_white_img = digit_black_and_white_img/255\n","\n","      digit_black_and_white_img = np.expand_dims(digit_black_and_white_img, (0,3))\n","\n","      pred = digit_recognition_model.predict(digit_black_and_white_img)\n","      \n","      if pred[0][pred.argmax()]>0.7:\n","        digits.append(pred.argmax())\n","\n","  number = \"\".join([str(digit) for digit in digits])\n","  return number"],"metadata":{"id":"1WvVSbXEmr07","executionInfo":{"status":"ok","timestamp":1673815681536,"user_tz":-120,"elapsed":228,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def count_nonblack_pixels(img):\n","    return img.any(axis=-1).sum()"],"metadata":{"id":"3rU0aWc466mo","executionInfo":{"status":"ok","timestamp":1673815756753,"user_tz":-120,"elapsed":2,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def detect_team(image):\n","\n","    color_list=['red','yellow','blue']\n","    ratios = []\n","\n","    boundaries = [\n","    ([17, 15, 100], [50, 56, 200]), #red\n","    ([25, 146, 190], [96, 174, 250]), #yellow\n","    ([43, 31, 4], [250, 88, 50]), #blue\n","    ]\n","    \n","    i = 0\n","    for (lower, upper) in boundaries:\n","\n","        lower = np.array(lower, dtype = \"uint8\")\n","        upper = np.array(upper, dtype = \"uint8\")\n","\n","\n","        mask = cv2.inRange(image, lower, upper)\n","        output = cv2.bitwise_and(image, image, mask = mask)\n","        tot_pix = count_nonblack_pixels(image)\n","        color_pix = count_nonblack_pixels(output)\n","        ratio = color_pix/tot_pix\n","        ratios.append(ratio)\n","        i += 1\n","\n","    if np.max(ratios) < 0.015:\n","      return 'not sure'   \n","    return color_list[np.argmax(ratios)]"],"metadata":{"id":"sQSxnXD57GWP","executionInfo":{"status":"ok","timestamp":1673815759290,"user_tz":-120,"elapsed":473,"user":{"displayName":"alex dan","userId":"11093049752083971773"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["writer = None\n","\n","h, w = None, None\n","\n","min_prob = 0.5\n","\n","colors={\n","    'blue':(255,0,0),\n","    'red':(0,0,255),\n","    'green':(0,255,0),\n","    'yellow':(0,255,255),\n","}\n","\n","video = cv2.VideoCapture('data/input_video.mp4')\n","\n","network = cv2.dnn.readNet('yolov3.weights','darknet/cfg/yolov3.cfg')\n","network.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n","\n","ln = network.getLayerNames()\n","ln = [ln[i - 1] for i in network.getUnconnectedOutLayers()]\n","\n","while True:\n","  ret, frame = video.read()\n","  if not ret:\n","      break\n","  \n","\n","  boxes = []\n","  box_colors = []\n","  bboxes={}\n","  confidences = []\n","  classIDs = []\n","  h, w = frame.shape[:2]\n","  \n","  blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n","  network.setInput(blob)\n","  outputs = network.forward(ln)\n","\n","  for output in outputs:\n","      for detection in output:\n","          scores = detection[5:]\n","          classID = np.argmax(scores)\n","          confidence = scores[classID]\n","\n","\n","          if confidence > 0.5:\n","            box = detection[:4] * np.array([w, h, w, h])\n","            (centerX, centerY, width, height) = box.astype(\"int\")\n","            x = int(centerX - (width / 2))\n","            y = int(centerY - (height / 2))\n","            box = [x, y, int(width), int(height)]\n","\n","            player_image = frame[y:y+int(height), x:x+int(width)]\n","            if player_image.shape[0] == 0 or player_image.shape[1] == 0 or player_image.shape[2] == 0:\n","                    continue\n","            boxes.append(box)\n","            confidences.append(float(confidence))\n","            classIDs.append(classID)\n","\n","            color = detect_team(player_image)\n","            box_colors.append(color) \n","            try:\n","              number_bboxes = detect_jersey_number(player_image)\n","              for b in number_bboxes:\n","                X,Y,W,H = b[0], b[1], b[2], b[3]\n","                number = identify_number(frame[y+Y:y+Y+H, x+X:x+X+W])\n","                cv2.rectangle(frame, (x+X,y+Y), (x+X+W, y+Y+H), (36,255,12), 2)\n","                cv2.putText(frame, f'Number {number}',(x-10, y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n","              bboxes[len(boxes)-1] = number_bboxes\n","            except Exception:\n","              pass\n","            \n","  indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","  \n","  if len(indices) > 0:\n","    for i in indices.flatten():\n","          box = boxes[i]\n","\n","          if classIDs[i] == 0:\n","              color = (0, 0, 0)\n","              text = 'GK/REF'\n","              if box_colors[i] != 'not sure':\n","                color = colors[box_colors[i]]\n","              if box_colors[i] == 'red':\n","                text = 'Belgium'\n","              if box_colors[i] == 'blue':\n","                text = 'France'\n","              if box_colors[i] == 'yellow':\n","                text = 'GK'\n","\n","              cv2.rectangle(frame, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), color, 2)\n","              cv2.putText(frame, text, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","\n","  if writer is None:\n","        resultVideo = cv2.VideoWriter_fourcc(*'mp4v')\n","\n","        \n","        writer = cv2.VideoWriter('data/output_video.mp4', resultVideo, 24.0,\n","                                (frame.shape[1], frame.shape[0]), True)\n","\n","  \n","  writer.write(frame)\n","\n","\n","video.release()\n","writer.release()"],"metadata":{"id":"wJFSjzpUY0kx"},"execution_count":null,"outputs":[]}]}